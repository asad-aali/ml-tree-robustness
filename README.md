# Robust Machine Learning

This is a research project (UT Austin) advised by Dr. Constantine Caramanis on Robustness against Adversarial Attacks on Tree-Based Machine Learning algorithms. This code is an implementation of ideas presented in the following research paper.

Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers - https://arxiv.org/pdf/2003.01031.pdf

Work:
- Used Shapley values to inject watermarks in high‚Äêdensity samples, creating a poisoning attack with a misclassification rate of 10.7%
- Leveraged isolation forests to identify watermarked samples and defend against the attack, reducing the misclassification rate to 0.1%
